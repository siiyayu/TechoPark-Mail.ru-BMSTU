{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andrewbelyaev/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import NMF, TruncatedSVD\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import pymorphy2\n",
    "from gensim.models import Word2Vec\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "import razdel\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import pymorphy2\n",
    "import gensim\n",
    "from tqdm import tqdm_notebook\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting razdel\n",
      "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: razdel\n",
      "Successfully installed razdel-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>m.kp.md</td>\n",
       "      <td>Экс-министр экономики Молдовы - главе МИДЭИ, ц...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>www.kp.by</td>\n",
       "      <td>Эта песня стала известна многим телезрителям б...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fanserials.tv</td>\n",
       "      <td>Банши 4 сезон 2 серия Бремя красоты смотреть о...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>colorbox.spb.ru</td>\n",
       "      <td>Не Беси Меня Картинки</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tula-sport.ru</td>\n",
       "      <td>В Новомосковске сыграют следж-хоккеисты алекси...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id              url                                              title  \\\n",
       "0   0          m.kp.md  Экс-министр экономики Молдовы - главе МИДЭИ, ц...   \n",
       "1   1        www.kp.by  Эта песня стала известна многим телезрителям б...   \n",
       "2   2    fanserials.tv  Банши 4 сезон 2 серия Бремя красоты смотреть о...   \n",
       "3   3  colorbox.spb.ru                              Не Беси Меня Картинки   \n",
       "4   4    tula-sport.ru  В Новомосковске сыграют следж-хоккеисты алекси...   \n",
       "\n",
       "   target  \n",
       "0   False  \n",
       "1   False  \n",
       "2   False  \n",
       "3   False  \n",
       "4   False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135309</td>\n",
       "      <td>www.kommersant.ru</td>\n",
       "      <td>Шестой кассационный суд в Самаре начнет работу...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135310</td>\n",
       "      <td>urexpert.online</td>\n",
       "      <td>Что такое индексация алиментов, кем и в каких ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135311</td>\n",
       "      <td>imperimeha.ru</td>\n",
       "      <td>Женщинам | Империя Меха - Part 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135312</td>\n",
       "      <td>national-porn.com</td>\n",
       "      <td>Небритые, волосатые киски: Порно всех стран и ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135313</td>\n",
       "      <td>2gis.ru</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                url  \\\n",
       "0  135309  www.kommersant.ru   \n",
       "1  135310    urexpert.online   \n",
       "2  135311      imperimeha.ru   \n",
       "3  135312  national-porn.com   \n",
       "4  135313            2gis.ru   \n",
       "\n",
       "                                               title  \n",
       "0  Шестой кассационный суд в Самаре начнет работу...  \n",
       "1  Что такое индексация алиментов, кем и в каких ...  \n",
       "2                  Женщинам | Империя Меха - Part 12  \n",
       "3  Небритые, волосатые киски: Порно всех стран и ...  \n",
       "4                                                 67  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    118594\n",
       "True      16715\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[\"title\"].values\n",
    "X_test = test_df[\"title\"].values\n",
    "y_train = train_df[\"target\"].astype(int).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [int(\"порно\" in text) for text in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31242758551206484"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,target\n",
      "135309,False\n",
      "135310,False\n",
      "135311,False\n",
      "135312,False\n",
      "135313,False\n",
      "135314,False\n",
      "135315,False\n",
      "135316,False\n",
      "135317,False\n",
      "cat: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "test_df[\"target\"] = [(\"порно\" in text) for text in X_test]\n",
    "\n",
    "test_df[[\"id\", \"target\"]].to_csv(\"simple_baseline.csv\", index=False)\n",
    "\n",
    "!cat simple_baseline.csv | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Не все так однозначно\n",
    "\n",
    "**не порно**:\n",
    "- Болезни опорно-двигательной системы и импотенция: взаимосвязь\n",
    "- Транссексуальные рыбы - National Geographic Россия: красота мира в каждом кадре\n",
    "- Групповая обзорная экскурсия по Афинам - цена €50\n",
    "- Больного раком Задорнова затравили в соцсетях.\n",
    "- Гомосексуалисты на «Первом канале»? Эрнст и Галкин – скрытая гей-пара российского шоу-бизнеса | Заметки о стиле, моде и жизни\n",
    "\n",
    "**порно**:\n",
    "- Отборная домашка\n",
    "- Сюзанна - карьера горничной / Susanna cameriera perversa (с русским переводом) 1995 г., DVDRip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_classifier(vectorizer, classifier):\n",
    "    return Pipeline(\n",
    "            [(\"vectorizer\", vectorizer),\n",
    "            (\"classifier\", classifier)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "<class 'sklearn.feature_extraction.text.CountVectorizer'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.943034670734541\n",
      "\n",
      "\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "0.9144887808196971\n",
      "\n",
      "\n",
      "<class 'sklearn.svm._classes.LinearSVC'>\n",
      "<class 'sklearn.feature_extraction.text.CountVectorizer'>\n",
      "0.951810068505077\n",
      "\n",
      "\n",
      "<class 'sklearn.svm._classes.LinearSVC'>\n",
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "0.9548248687376308\n",
      "\n",
      "\n",
      "<class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'>\n",
      "<class 'sklearn.feature_extraction.text.CountVectorizer'>\n",
      "0.9423192603057672\n",
      "\n",
      "\n",
      "<class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'>\n",
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "0.8927790186977494\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf in [LogisticRegression, LinearSVC, SGDClassifier]:\n",
    "    for vect in [CountVectorizer, TfidfVectorizer]:\n",
    "        print(clf)\n",
    "        print(vect)\n",
    "        print(cross_val_score(text_classifier(vect(), clf()), X_train, y_train, cv=5, scoring='f1').mean())\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfIdfVectorizer, LogisticRegression: 0.902\n",
      "CountVectorizer, LogisticRegression: 0.943\n",
      "TfIdfVectorizer, MultinomialGaussian: 0.898\n",
      "CountVectorizer, MultinomialGaussian: 0.837\n",
      "TfIdfVectorizer, SGDClassifier: 0.882\n",
      "CountVectorizer, SGDClassifier: 0.943\n",
      "TfIdfVectorizer, LinearSVC: 0.883\n",
      "CountVectorizer, LinearSVC: 0.952\n"
     ]
    }
   ],
   "source": [
    "print('TfIdfVectorizer, LogisticRegression:', round(0.9022925463226912, 3))\n",
    "print('CountVectorizer, LogisticRegression:', round(0.943034670734541, 3))\n",
    "print('TfIdfVectorizer, MultinomialGaussian:', round(0.8981449177149763, 3))\n",
    "print('CountVectorizer, MultinomialGaussian:', round(0.8371649914733172, 3))\n",
    "print('TfIdfVectorizer, SGDClassifier:', round(0.8823506407703879, 3))\n",
    "print('CountVectorizer, SGDClassifier:', round(0.9428561918803572, 3))\n",
    "print('TfIdfVectorizer, LinearSVC:', round(0.8826559337315283, 3))\n",
    "print('CountVectorizer, LinearSVC:', round(0.951810068505077, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,target\n",
      "135309,False\n",
      "135310,False\n",
      "135311,False\n",
      "135312,True\n",
      "135313,False\n",
      "135314,False\n",
      "135315,False\n",
      "135316,False\n",
      "135317,False\n",
      "cat: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "    \n",
    "test_df[\"target\"] = model.predict(X_test_vectorized).astype(bool)\n",
    "\n",
    "test_df[[\"id\", \"target\"]].to_csv(\"ml_baseline.csv\", index=False)\n",
    "\n",
    "!cat ml_baseline.csv | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>m.kp.md</td>\n",
       "      <td>Экс-министр экономики Молдовы - главе МИДЭИ, ц...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>www.kp.by</td>\n",
       "      <td>Эта песня стала известна многим телезрителям б...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fanserials.tv</td>\n",
       "      <td>Банши 4 сезон 2 серия Бремя красоты смотреть о...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>colorbox.spb.ru</td>\n",
       "      <td>Не Беси Меня Картинки</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tula-sport.ru</td>\n",
       "      <td>В Новомосковске сыграют следж-хоккеисты алекси...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id              url                                              title  \\\n",
       "0   0          m.kp.md  Экс-министр экономики Молдовы - главе МИДЭИ, ц...   \n",
       "1   1        www.kp.by  Эта песня стала известна многим телезрителям б...   \n",
       "2   2    fanserials.tv  Банши 4 сезон 2 серия Бремя красоты смотреть о...   \n",
       "3   3  colorbox.spb.ru                              Не Беси Меня Картинки   \n",
       "4   4    tula-sport.ru  В Новомосковске сыграют следж-хоккеисты алекси...   \n",
       "\n",
       "   target  \n",
       "0   False  \n",
       "1   False  \n",
       "2   False  \n",
       "3   False  \n",
       "4   False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135309</td>\n",
       "      <td>www.kommersant.ru</td>\n",
       "      <td>Шестой кассационный суд в Самаре начнет работу...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135310</td>\n",
       "      <td>urexpert.online</td>\n",
       "      <td>Что такое индексация алиментов, кем и в каких ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135311</td>\n",
       "      <td>imperimeha.ru</td>\n",
       "      <td>Женщинам | Империя Меха - Part 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135312</td>\n",
       "      <td>national-porn.com</td>\n",
       "      <td>Небритые, волосатые киски: Порно всех стран и ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135313</td>\n",
       "      <td>2gis.ru</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                url  \\\n",
       "0  135309  www.kommersant.ru   \n",
       "1  135310    urexpert.online   \n",
       "2  135311      imperimeha.ru   \n",
       "3  135312  national-porn.com   \n",
       "4  135313            2gis.ru   \n",
       "\n",
       "                                               title  \n",
       "0  Шестой кассационный суд в Самаре начнет работу...  \n",
       "1  Что такое индексация алиментов, кем и в каких ...  \n",
       "2                  Женщинам | Империя Меха - Part 12  \n",
       "3  Небритые, волосатые киски: Порно всех стран и ...  \n",
       "4                                                 67  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_set = set(nltk.corpus.stopwords.words('russian'))\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=33)\n",
    "corpus = df.title.values\n",
    "TOKEN_PATTERN = \"[а-яё]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ed05bfcf114a7196d4f3f093126eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=135309.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = pymorphy2.MorphAnalyzer()\n",
    "lemmatizer_cache = {}\n",
    "\n",
    "def lemmatize(token):\n",
    "    if lemmatizer.word_is_known(token):\n",
    "        if token not in lemmatizer_cache:\n",
    "            lemmatizer_cache[token] = lemmatizer.parse(token)[0].normal_form\n",
    "        return lemmatizer_cache[token]\n",
    "    return token\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(TOKEN_PATTERN, text.lower())\n",
    "\n",
    "docs = [tokenize(text) for text in corpus]\n",
    "\n",
    "lemmatized_docs = [[lemmatize(token) for token in text] for text in tqdm_notebook(docs)]\n",
    "\n",
    "cleared_docs = [[token for token in text if token not in stopword_set] for text in lemmatized_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745fc888ee7e4ead969e42c48804529a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=135309.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def prepare_sentence_dataset(documents):\n",
    "    tokenized_sentences = []\n",
    "    for document in tqdm_notebook(documents):\n",
    "        for sentence in razdel.sentenize(document):\n",
    "            lemmatized_tokens = [lemmatize(token) for token in re.findall(TOKEN_PATTERN, sentence.text.lower())]\n",
    "            tokenized_sentences.append(\n",
    "                [token for token in lemmatized_tokens if token not in stopword_set]\n",
    "            )\n",
    "    return tokenized_sentences\n",
    "\n",
    "sentence_dataset = prepare_sentence_dataset(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = gensim.models.Word2Vec(size=100, sg=0, window=5, min_count=5, negative=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec.build_vocab(sentence_dataset, progress_per=20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14552"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2vec.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19749040, 24067650)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.train(sentence_dataset, total_examples=word2vec.corpus_count, epochs=30, report_delay=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text(text, word2index, word_embeddings):\n",
    "    if text:\n",
    "        return np.array([\n",
    "            word_embeddings[word2index[word]] for word in text \n",
    "            if word in word2index and word not in stopword_set\n",
    "        ]).mean(0, keepdims=True)\n",
    "    else:\n",
    "        return np.array([0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2word = np.array(word2vec.wv.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {word: i for i, word in enumerate(index2word)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = word2vec.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: Mean of empty slice.\n",
      "  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 8 has 1 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-11e9c1386327>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtalk2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membed_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcleared_docs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 8 has 1 dimension(s)"
     ]
    }
   ],
   "source": [
    "talk2vec = np.concatenate([embed_text(doc, word2index, embeddings) for doc in cleared_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: Mean of empty slice.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "temp = [embed_text(doc, word2index, embeddings) for doc in cleared_docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.9579274 , -0.19552569,  0.12991357, -1.2130126 , -1.2676915 ,\n",
       "         0.09772716,  0.367435  , -0.8844541 , -0.16925658,  0.14679837,\n",
       "        -0.17489839,  0.59845716, -0.514643  ,  0.08787344,  0.511462  ,\n",
       "        -0.49592334,  0.09322026,  0.39677015, -0.16357838, -0.04230067,\n",
       "         0.08262321,  0.16353706,  0.255459  ,  0.23290433, -0.11814594,\n",
       "        -0.3154427 ,  0.5331477 ,  0.71619475, -0.68402183, -0.03167564,\n",
       "         0.28365666, -0.10813255, -0.52118397,  0.15937798,  0.80914444,\n",
       "         0.080773  ,  0.31100363,  0.12590824,  0.11027858, -0.9290128 ,\n",
       "         0.2032516 , -0.59428245,  0.68092996,  0.5948286 , -0.57708323,\n",
       "        -0.02585703, -0.5006824 ,  0.34709507, -0.03487219,  0.4998681 ,\n",
       "         0.04564488,  0.20185913,  0.7175542 ,  0.06063968,  0.4405706 ,\n",
       "        -0.42066208, -0.7639802 , -0.11414336,  0.6829329 ,  0.4661962 ,\n",
       "         0.39259174, -0.35498926, -0.32780102, -0.03257314,  1.1233091 ,\n",
       "        -0.8812305 ,  0.00615256, -0.09289372,  0.14144163,  0.34599122,\n",
       "         0.29676113, -0.16161087, -0.63746727, -0.1170251 ,  0.02426836,\n",
       "         1.2267816 ,  0.12780534, -0.25940144,  0.42788145, -0.7163135 ,\n",
       "        -0.3225217 , -0.7400729 ,  0.14516906, -1.1283098 , -0.7173675 ,\n",
       "         0.12273695, -1.0812567 ,  0.60543025, -0.05194949, -0.9195346 ,\n",
       "         0.54575795, -0.70494133,  0.10318502,  0.14481483,  0.1793078 ,\n",
       "        -0.5564241 ,  0.64457864,  0.6273035 ,  0.19428803,  0.14949529]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_text(cleared_docs[0], word2index, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "if cleared_docs[8]:\n",
    "    print(1)\n",
    "else:\n",
    "    print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: Mean of empty slice.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_text(cleared_docs[8], word2index, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(n_estimators=100, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
